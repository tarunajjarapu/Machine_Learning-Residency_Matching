{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "filtered_data = data_without_specialty_or_year\n",
    "\n",
    "X = filtered_data[['No of Offered Positions', 'No of Total Applicants']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['No of Offered Positions'], \n",
    "            filtered_data['No of Total Applicants'])\n",
    "plt.xlabel('No of Offered Positions')\n",
    "plt.ylabel('No of Total Applicants')\n",
    "plt.title('No of Offered Positions vs No of Total Applicants after Isolation Forest Outlier Removal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "mlp_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPRegressor(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(30,), (40,), (50,), (60,)],\n",
    "    'mlp__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "# hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_Nnet = grid_search.best_estimator_\n",
    "\n",
    "y_test_pred_nnet = best_Nnet.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Linear Regression', 'Decision Tree', 'Random Forest', 'KNN', 'Neural Network']\n",
    "model_vals = [y_test_pred_lr, y_test_pred_dtr, y_test_pred_rfr, y_test_pred_knn, y_test_pred_nnet]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Model {models[i]} MSE: {mean_squared_error(y_test, model_vals[i])}\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Model {models[i]} R^2 Score: {r2_score(y_test, model_vals[i])}\")\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.scatter(y_test, model_vals[i], alpha=0.7)\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(f'Model {models[i]} Predictions')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:24:26.000741Z",
     "start_time": "2024-12-08T20:24:25.990353Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Residency Match and Scramble\n",
    "The main residency match is a process where medical school graduates apply for positions in residency programs, which are required for specialization in medicine. Applicants rank their preferred programs, and residency programs rank the applicants they wish to offer positions to. The match is then conducted using an algorithm by the National Resident Matching Program (NRMP), which pairs applicants with programs based on these rankings. However, not all applicants are matched to a position due to the high competition. If this occurs, they enter the SOAP (Supplemental Offer and Acceptance Program), a \"scramble\" period, where unmatched applicants can apply for unfilled positions through an intense and expedited process. Applicants only learn which specialty programs have unfilled positions after the matching algorithm results are released, which takes months. To address the uncertainty of what options are available during the \"scramble,\" we will use supervised machine learning to predict how many unfilled positions each specialty will have, based on features known prior to the matching algorithm. As a result, applicants will be able to know before the Match Day about the likely number of positions under each specialty type that would be available to them in the “scramble” process, in the case that they are unmatched. \n",
    "\n",
    "While final-year students of US medical schools (US seniors) are a large percentage of the Match applicants, they are not the only demographic involved. International medical school and DO school students/graduates also apply for these residency programs and tend to be subject to the SOAP process more often than US seniors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Importing and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:08:59.763913Z",
     "start_time": "2024-12-08T03:08:59.744054Z"
    }
   },
   "outputs": [],
   "source": [
    "fulldata = pd.read_csv('2024-2015MainResidencyMatchData.csv')\n",
    "fulldata.head()\n",
    "\n",
    "# Some of the entries had 0 offered positions and these were removed as they are not relevant to the analysis\n",
    "fulldata = fulldata[fulldata != '#DIV/0!'].dropna()\n",
    "\n",
    "#Checking for duplicates, but there are none\n",
    "print(fulldata.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data Features\n",
    "Significant Data cleaning and preparation was required before the final csv file of the data was formed. The raw data was obtained from appending data tables together found from the NRMP's yearly reports on the Main Residency Match Data. Combining the datafrom 10 past years made the size of the dataset more favorable to run ML agorithms on it reliably.\n",
    "The data tables from 2015-2023 consisted of the following attributes:\n",
    "1. Specialty\t\n",
    "2. No Programs\tPositions Offered\n",
    "3. Unfilled Programs\n",
    "4. US Senior Applicants\n",
    "5. Total Applicants\n",
    "6. No of US Senior Matches\n",
    "7. No of Total Matches\n",
    "8. % Filled by US Seniors\n",
    "9. % Filled Total\n",
    "10. Ranked Positions by US Seniors\n",
    "11. Total Ranked Positions\n",
    "\n",
    "However, the 2024 data table was structured differently, with different attributes but essentially similar information was conveyed. \n",
    "In order to combine the information, new features were created and others removed, leading to the fnialized engineered data as seen in the csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "The original data included features such as 'No of Total Matches', and '% Filled by Seniors'. However, we want to use the model as an indicator of the number of unfilled positions in each specialty prior without having to rely on the NRMP Matching algorithm, so any data related to post-match metrics got dropped. This left even fewer features remaining, so feature engineering was used to create the following features from existing data:\n",
    "\n",
    "4. Applicants per Position Ratio =  No of Total Applicants to Specialty / No of Offered Positions for Specialty\n",
    "5. No Programs for Specialty to All Programs Ratio = No of Programs for Specialty/ Total PGY-1 No of Programs for Given Year\n",
    "6. US MD Senior Applicants to Total Applicants Ratio = No of Senior Applicants to Specialty / No of Total Applicants to Specialty\n",
    "7. Avg Program Size (in number of positions) = No of Offered Positions for Specialty / No of Programs for Specialty\n",
    "8. No of Applications to the Specialty to All Applications Ratio = No of Total Applicants to Specialty/ Total PGY-1 No of Total Applicants for Given Year\n",
    "\n",
    "\n",
    "\n",
    "The following table outlines the features used to predict or explain the target variable **\"Unfilled Positions\"**\n",
    "\n",
    "| **Feature**                                       | **How it was Calculated**                                            | **Intuition/Significance**                                               |\n",
    "|--------------------------------------------------|---------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
    "| **1. Specialty**                                  | Specialty                                                           | This feature represents the specific medical specialty under consideration. It's a categorical variable that helps identify which specialty is being analyzed. |\n",
    "| **2. Unfilled Positions**                         | Target variable to predict                                          | The number of positions that remain unfilled in the given specialty. This is the main target of prediction in the machine learning model. |\n",
    "| **3. No of Offered Positions**                   | Number of Offered Positions for the Specialty                        | This feature measures the supply of positions available for a given specialty. It gives an idea of how many positions are being offered for that specialty in a given year. |\n",
    "| **4. No of Total Applicants**                    | Number of Total Applicants to the Specialty                          | This feature indicates the demand for positions in a specialty, representing how many applicants are interested in that specialty. |\n",
    "| **5. Applicants per Position Ratio**              | Number of Total Applicants to Specialty / Number of Offered Positions for Specialty | This ratio shows the competitiveness of positions in the specialty. A higher ratio indicates more applicants per available position, suggesting higher competition. |\n",
    "| **6. No Programs for Specialty to All Programs Ratio** | Number of Programs for Specialty / Total PGY-1 Number of Programs for the Given Year | This ratio shows the \"commonness\" of a specialty. A higher ratio means the specialty is more common (more programs available), while a lower ratio suggests it is rarer. |\n",
    "| **7. US MD Senior Applicants to Total Applicants Ratio** | Number of Senior Applicants to Specialty / Number of Total Applicants to Specialty | This feature indicates the desirability of the specialty. A higher ratio means more senior US MD applicants are applying, which indicates a more sought-after specialty (US MD applicants are generally preferred by residency programs to other types of applicants so have a competitive advantage). |\n",
    "| **8. Avg Program Size (in number of positions)** | Number of Offered Positions for Specialty / Number of Programs for Specialty | This feature reflects the average size of programs within the specialty. Larger average program sizes may indicate greater opportunities for applicants to match. |\n",
    "| **9. No of Applications to the Specialty to All Applications Ratio** | Number of Total Applicants to Specialty / Total PGY-1 Number of Total Applicants for the Given Year | This ratio measures the popularity of a specialty. A higher ratio indicates that the specialty is more popular compared to others because it received relatively more applications. |\n",
    "| **10. Year**                                       | Year                                                                | This is simply the year of the data. It may help capture trends or changes in patterns related to unfilled positions over the time frame of 2015 to 2024. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:08:59.790307Z",
     "start_time": "2024-12-08T03:08:59.765437Z"
    }
   },
   "outputs": [],
   "source": [
    "print(fulldata.shape)\n",
    "data= fulldata[~fulldata['Specialty'].str.contains('Total PGY-1')] # is not a real specialty, just a total row for the year\n",
    "print(data.shape)\n",
    "print('Number of Specialties',len(data['Specialty'].unique()))\n",
    "data = pd.get_dummies(data, columns=['Specialty', 'Year']) # One hot encoding the specialties and years as they are categorical\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:08:59.815769Z",
     "start_time": "2024-12-08T03:08:59.802285Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(data.shape) # 10 original columns, -1 Specialty, + 54 dummy Specialties, -1 Year, + 10 dummy Years = 72 columns now\n",
    "avoid = set(['Specialty', 'Year', 'Unfilled Positions'])\n",
    "data_without_specialty_or_year=data.drop(columns=[col for col in data.columns if 'Specialty' in col or 'Year' in col], inplace=False)\n",
    "correlation_data=data.drop(columns=[col for col in data.columns if 'Specialty_' in col or 'Year_' in col or 'Unfilled Positions' in col], inplace=False)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "correlations = pd.DataFrame(scaler.fit_transform(correlation_data), columns=correlation_data.columns).corr()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Features')\n",
    "plt.title('HeatMap for Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation is not close enough to +/-1 between any two variables that they would be obviously redundant, except for No of Total Applicants and No of Offered Positions. However, considering how likely both of these features are to be important in predicting the target variable, it is best to keep them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'No of Applications to Specialty to All Applications Ratio' as it's correlations with the other features are almost the exact same as 'No of Total Applications'\n",
    "data = data.drop(columns=['No of Applications to Specialty to All Applications Ratio']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = correlations.stack()\n",
    "correlations = correlations.reset_index()\n",
    "correlations.columns = ['feature_1', 'feature_2', 'correlation']\n",
    "\n",
    "correlations = correlations.query('feature_1 != feature_2')\n",
    "print ( correlations.iloc[correlations['correlation'].abs().argsort()[::-1]].head(20) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:00.096128Z",
     "start_time": "2024-12-08T03:08:59.892625Z"
    }
   },
   "outputs": [],
   "source": [
    "data_without_specialty_or_year.plot.scatter(x='No of Offered Positions', y='No of Total Applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection and Removal\n",
    "\n",
    "After "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "filtered_data = data_without_specialty_or_year\n",
    "\n",
    "X = filtered_data[['No of Offered Positions', 'No of Total Applicants']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['No of Offered Positions'], \n",
    "            filtered_data['No of Total Applicants'])\n",
    "plt.xlabel('No of Offered Positions')\n",
    "plt.ylabel('No of Total Applicants')\n",
    "plt.title('No of Offered Positions vs No of Total Applicants after Isolation Forest Outlier Removal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are similar but there is some variation so it should be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:00.180182Z",
     "start_time": "2024-12-08T03:09:00.121838Z"
    }
   },
   "outputs": [],
   "source": [
    "data_without_specialty_or_year.plot.scatter(x='No of Offered Positions', y='Unfilled Positions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data[['No of Offered Positions', 'Unfilled Positions']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['No of Offered Positions'], \n",
    "            filtered_data['Unfilled Positions'])\n",
    "plt.xlabel('No of Offered Positions')\n",
    "plt.ylabel('Unfilled Positions')\n",
    "plt.title('No of Offered Positions vs Unfilled Positions after Isolation Forest Outlier Removal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggests that few applicants means few unfilled positions, perhaps an indicator of selectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:00.289515Z",
     "start_time": "2024-12-08T03:09:00.223001Z"
    }
   },
   "outputs": [],
   "source": [
    "data_without_specialty_or_year.plot.scatter(x='No of Total Applicants', y='Unfilled Positions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = filtered_data[['No of Total Applicants', 'Unfilled Positions']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['No of Total Applicants'], \n",
    "            filtered_data['Unfilled Positions'])\n",
    "plt.xlabel('No of Total Applicants')\n",
    "plt.ylabel('Unfilled Positions')\n",
    "plt.title('No of Total Applicants vs Unfilled Positions after Isolation Forest Outlier Removal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggests that few applicants means few unfilled positions, perhaps an indicator of selectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:00.553684Z",
     "start_time": "2024-12-08T03:09:00.334040Z"
    }
   },
   "outputs": [],
   "source": [
    "data_without_specialty_or_year.plot.scatter(x='Applicants per Position Ratio', y='Unfilled Positions')\n",
    "plt.xticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = filtered_data[['Applicants per Position Ratio', 'Unfilled Positions']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['Applicants per Position Ratio'], \n",
    "            filtered_data['Unfilled Positions'])\n",
    "plt.xlabel('Applicants per Position Ratio')\n",
    "plt.ylabel('Unfilled Positions')\n",
    "plt.title('Applicants per Position Ratio vs Unfilled Positions after Isolation Forest Outlier Removal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not a clear relationship between the two features, but it shows there is some consistency in the number of Applicants per Position, regardless of the outcome of unfilled positinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:00.619849Z",
     "start_time": "2024-12-08T03:09:00.558063Z"
    }
   },
   "outputs": [],
   "source": [
    "data_without_specialty_or_year.plot.scatter(x='US MD Senior Applicants to Total Applicants Ratio', y='Unfilled Positions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data[['US MD Senior Applicants to Total Applicants Ratio', 'Unfilled Positions']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['US MD Senior Applicants to Total Applicants Ratio'], \n",
    "            filtered_data['Unfilled Positions'])\n",
    "plt.xlabel('US MD Senior Applicants to Total Applicants Ratio')\n",
    "plt.ylabel('Unfilled Positions')\n",
    "plt.title('US MD Senior Applicants to Total Applicants Ratio vs Unfilled Positions after Isolation Forest Outlier Removal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, when the US MD Senior Applicants Ratio is higher, there is often fewer unfilled positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:00.684889Z",
     "start_time": "2024-12-08T03:09:00.630111Z"
    }
   },
   "outputs": [],
   "source": [
    "data_without_specialty_or_year.plot.scatter(x='Avg Program Size', y='Unfilled Positions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data[['Avg Program Size', 'Unfilled Positions']].values\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05) \n",
    "\n",
    "filtered_data['outlier'] = iso_forest.fit_predict(X)\n",
    "\n",
    "filtered_data = filtered_data[filtered_data['outlier'] == 1].drop(columns=['outlier'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['Avg Program Size'], \n",
    "            filtered_data['Unfilled Positions'])\n",
    "plt.xlabel('Avg Program Size')\n",
    "plt.ylabel('Unfilled Positions')\n",
    "plt.title('Avg Program Size vs Unfilled Positions after Isolation Forest Outlier Removal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, when the program size is small it seems there are usually little to no unfilled positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T03:09:01.143309Z",
     "start_time": "2024-12-08T03:09:00.696612Z"
    }
   },
   "outputs": [],
   "source": [
    "#bar graph for specialties:\n",
    "specialty_columns = [col for col in data.columns if 'Specialty_' in col]\n",
    "print(specialty_columns)\n",
    "avg_unfilled_positions_per_specialty=[] #the average over the years\n",
    "for specialty in specialty_columns:\n",
    "    avg_unfilled_positions_per_specialty.append(data[data[specialty]==True]['Unfilled Positions'].mean())\n",
    "\n",
    "less_than_10 = [(specialty, avg) for specialty, avg in zip(specialty_columns, avg_unfilled_positions_per_specialty) if avg <= 10]\n",
    "greater_than_10 = [(specialty, avg) for specialty, avg in zip(specialty_columns, avg_unfilled_positions_per_specialty) if avg > 10]\n",
    "\n",
    "less_than_10 = reversed(sorted(less_than_10, key=lambda x: x[1]))\n",
    "greater_than_10 = reversed(sorted(greater_than_10, key=lambda x: x[1]))\n",
    "\n",
    "specialties_lt_10, values_lt_10 = zip(*less_than_10) if less_than_10 else ([], [])\n",
    "specialties_gt_10, values_gt_10 = zip(*greater_than_10) if greater_than_10 else ([], [])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(16, 20))\n",
    "\n",
    "# Plot for values <= 100\n",
    "ax1.bar(specialties_lt_10, values_lt_10)\n",
    "ax1.set_title('Specialties with Avg Unfilled Positions <= 10')\n",
    "ax1.set_xlabel('Specialty')\n",
    "ax1.set_ylabel('Average Unfilled Positions')\n",
    "ax1.set_xticklabels([x.split('_')[1] for x in specialties_lt_10], rotation=90, fontsize=12)\n",
    "\n",
    "# Plot for values > 100\n",
    "ax2.bar(specialties_gt_10, values_gt_10)\n",
    "ax2.set_title('Specialties with Avg Unfilled Positions > 10')\n",
    "ax2.set_xlabel('Specialty')\n",
    "ax2.set_ylabel('Average Unfilled Positions')\n",
    "ax2.set_xticklabels([x.split('_')[1] for x in specialties_gt_10], rotation=90, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These histograms aren't very helpful for picking out trends, but are useful for highlighting the large discrepancies in the number of unfilled positions between specialties as well as highlighting and making it easier to parse the predictions and residuals later on. A higher absolute error is more acceptable for specialties with a higher average number of unfilled positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bar graph for yearly trends\n",
    "year_totals = fulldata[fulldata['Specialty']=='Total PGY-1']['Unfilled Positions']\n",
    "years = fulldata[fulldata['Specialty']=='Total PGY-1']['Year']\n",
    "\n",
    "fig2, ax = plt.subplots(figsize=(8,5))\n",
    "ax.bar(years, year_totals)\n",
    "ax.set_title('Unfilled Positions by Year')\n",
    "ax.set_ylabel('Num Unfilled Positions')\n",
    "ax.set_xlabel('Year')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The graph for unfilled positions by year shows a clear trend that the number of unfilled positions is increasing which highlights that this is an important feature to consider in the model as the year will definitely have an impact on the number of unfilled positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training / Test data split\n",
    "data_encoded = data\n",
    "X = data_encoded.drop(['Unfilled Positions'], axis=1)\n",
    "y = data_encoded['Unfilled Positions']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression\n",
    "Since the decision trees can split based on the average program size and competitiveness, the decision tree can help seperate out the data point to predict it based on similar previous datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:04:48.054322Z",
     "start_time": "2024-12-08T04:02:43.919760Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': range(1, 21, 2),\n",
    "    'min_samples_split': range(2, 11, 2),\n",
    "    'min_samples_leaf': range(1, 11, 2),\n",
    "    'max_features': range(1, 11),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=tree, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "cross_val_DTR = -1 * cross_val_score(grid, X, y, cv=5, verbose=True)\n",
    "print(f\"Cross Val Score: {cross_val_DTR.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:07:55.243125Z",
     "start_time": "2024-12-08T04:07:55.239918Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cross_val_DTR.mean() / len(y))\n",
    "print(cross_val_DTR / len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "We used linear regression to identify linear trends between our features like and how it may related to unfilled positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:04:48.185496Z",
     "start_time": "2024-12-08T04:04:48.120174Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "linreg = LinearRegression()\n",
    "pipeline = make_pipeline(scaler, linreg)\n",
    "\n",
    "cross_val_LR = -1 * cross_val_score(linreg, X, y, cv=5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:08:12.639890Z",
     "start_time": "2024-12-08T04:08:12.635599Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Cross Val Score: {cross_val_LR.mean() / len(y)}\")\n",
    "print(cross_val_LR / len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "We used random Forest to aggregate predictions from multiple Decision Trees to improve accuracy while using the most important features impacting unfilled positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:13:52.926482Z",
     "start_time": "2024-12-08T04:08:31.514029Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "params = {\n",
    "    'n_estimators': range(1, 20, 2),\n",
    "    'max_depth': range(1, 21, 3),\n",
    "    'min_samples_leaf': range(1, 11, 2),\n",
    "    'max_features': range(1, 11, 2)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=forest, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "cross_val_RFR = -1 * cross_val_score(grid, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:14:53.625968Z",
     "start_time": "2024-12-08T04:14:53.622058Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Cross Val Score: {cross_val_RFR.mean() / len(y)}\")\n",
    "print(cross_val_RFR / len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regressor\n",
    "We used KNN to find the similarity between specialties, predict unfilled positions based on features of the most similar specialties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:15:30.550552Z",
     "start_time": "2024-12-08T04:15:05.090587Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "params = {\n",
    "    'kneighborsregressor__n_neighbors': range(1, 21),\n",
    "    'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "    'kneighborsregressor__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "scale = StandardScaler()\n",
    "pipeline = make_pipeline(scale, knn)\n",
    "\n",
    "grid = GridSearchCV(estimator=pipeline, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "cross_val_KNN = -1 * cross_val_score(grid, X, y, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T04:17:19.458997Z",
     "start_time": "2024-12-08T04:17:19.445996Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Cross Val Score: {cross_val_KNN.mean() / len(y)}\")\n",
    "print(cross_val_KNN / len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net\n",
    "We used the Neural Network to balance out the complex interactions between features, such as competitiveness ratios and yearly trends, to predict unfilled positions with high flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T20:15:29.844081Z",
     "start_time": "2024-12-08T20:14:43.577895Z"
    }
   },
   "outputs": [],
   "source": [
    "# need to first use 5 fold CV to find best hidden layer size and best activation function\n",
    "# mostly taken straight from assignment 4 and modified\n",
    "mlp_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPRegressor(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(30,), (40,), (50,), (60,)],\n",
    "    'mlp__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "cross_val_Nnet = -1 * cross_val_score(grid_search, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cross Val Score: {cross_val_Nnet.mean() / len(y)}\")\n",
    "print(cross_val_Nnet / len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and plot the cross-validation scores all of the models\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "Cross_val_scores = [cross_val_DTR.mean() / len(y), cross_val_LR.mean() / len(y), cross_val_RFR.mean() / len(y), cross_val_KNN.mean() / len(y), cross_val_Nnet.mean() / len(y)]\n",
    "models = ['Decision Tree', 'Linear Regression', 'Random Forest', 'KNN', 'Neural Network']\n",
    "plt.bar(models, Cross_val_scores)\n",
    "plt.ylabel('Mean Cross Validation Score')\n",
    "plt.title('Cross Validation Scores of Different Models')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "linreg_graph = LinearRegression()\n",
    "linreg_graph.fit(X_train, y_train)\n",
    "y_test_pred_lr = linreg_graph.predict(X_test)\n",
    "\n",
    "# Print Corrpesponding Features\n",
    "for i in range(len(linreg_graph.coef_)):\n",
    "    print(f'{X.columns[i]}: {linreg_graph.coef_[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "DTR = DecisionTreeRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': range(1, 21, 2),\n",
    "    'min_samples_split': range(2, 11, 2),\n",
    "    'min_samples_leaf': range(1, 11, 2),\n",
    "    'max_features': range(1, 11),\n",
    "}\n",
    "\n",
    "grid_DTR = GridSearchCV(estimator=tree, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_DTR.fit(X_train, y_train)\n",
    "best_DTR = grid_DTR.best_estimator_\n",
    "\n",
    "y_test_pred_dtr = best_DTR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "RFR = RandomForestRegressor()\n",
    "\n",
    "params = {\n",
    "    'n_estimators': range(1, 20, 2),\n",
    "    'max_depth': range(1, 21, 3),\n",
    "    'min_samples_leaf': range(1, 11, 2),\n",
    "    'max_features': range(1, 11, 2)\n",
    "}\n",
    "\n",
    "grid_RFR = GridSearchCV(estimator=forest, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_RFR.fit(X_train, y_train)\n",
    "best_RFR = grid_RFR.best_estimator_\n",
    "\n",
    "y_test_pred_rfr = best_RFR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "params = {\n",
    "    'kneighborsregressor__n_neighbors': range(1, 21),\n",
    "    'kneighborsregressor__weights': ['uniform', 'distance'],\n",
    "    'kneighborsregressor__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create the pipeline\n",
    "scale = StandardScaler()\n",
    "pipeline = make_pipeline(scale, knn)\n",
    "\n",
    "# Set up GridSearchCV with the correct parameter grid\n",
    "grid_KNN = GridSearchCV(estimator=pipeline, param_grid=params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_KNN.fit(X_train, y_train)\n",
    "best_KNN = grid_KNN.best_estimator_\n",
    "\n",
    "y_test_pred_knn = best_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Linear regression had the lowest mean cross-validation score per entry (<0.1), indicating that it most accurately captures the underlying trends in the data compared to the other models.\n",
    "\n",
    "Analyzing the coefficients that contributed most to the final prediction, we found that the 'Number of Programs for Specialty to All Programs Ratio' (a measure of the percentage of applicants who applied to a specific specialty relative to the total number of applicants) was by far the most influential factor, with a coefficient of approximately -3200. The next most significant factor was the specific specialty to which applicants were applying. Specialties with the highest number of unfilled positions had the largest coefficients, which aligns with expectations.\n",
    "\n",
    "Decision Trees and KNNs performed similarly, ranking in the middle of the pack, while Random Forests had the worst performance of all the models we tested. We believe this is because these models rely on averaging values from groups of samples within the dataset. As seen in the Predicted vs. Actual Values graph, these models tend to overestimate on the lower end and underestimate on the higher end. Our dataset includes many specialties with very few offered positions and applicants, as well as a few specialties with a large number of positions and applicants, but there are relatively few data points in between. We suspect that the models are being influenced by outlier values from these two clusters, leading to inaccurate predictions. Additionally, the results from linear regression suggest that only a few features are truly impactful for the final prediction. This implies that decision trees may be overfitting to irrelevant features, further reducing their effectiveness.\n",
    "\n",
    "The Neural Network performed worse than linear regression but noticeably better than the other models. We believe this is because, like linear regression, the neural network attempts to approximate the underlying function that drives the data, rather than averaging previously observed values. This approach makes it less susceptible to the issues seen with models like Decision Trees and Random Forests.\n",
    "\n",
    "Overall, we were initially surprised by how well linear regression performed, as we had expected the other models to be more successful. However, after further analysis, the results make sense. With an R^2 value greater than 0.9 between actual and predicted values, we believe the linear regression model could be useful for accurately predicting future outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
